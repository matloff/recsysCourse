\chapter{Some Infrastructure: Probability and Statistics}
\label{chap:infra2}   

Many RS methods are probabilistic in nature, so we will lay out some
infrastructure.  It is assumed the reader has a background in
calculus-based probability structures, such as expected value and
density functions.  Background in statistics (as opposed to probability)
and machine learning is \textit{not} assumed.

\section{Data as a Sample}

In statistics, the data are usually considered a sample from a
population.  For instance, during an election campaign pollsters will
take a \underline{sample}, typically of 1200 people, from the
\underline{population} of all voters.  Say they are interested in $p$,
the population proportion of voters favoring Candidate Jones. They
calculate their \underline{estimate} of $p$, denoted $\widehat{p}$, to
be the proportion of voters in the \underline{sample} who like Jones.

Sometimes the notion of sampling is merely conceptual. Say for instance
we are studying hypertension, on data involving 1000 patients.  We think
of them as a sample from the population of all sufferers of
hypertension, even though we did not go through an actual sampling
process.

In RS contexts, this means that we treat the users in our dataset as a
sample from the conceptual population of all potential users.  We may
even treat the items as a sample from a conceptual population of all
possible items.

In machine learning circles, it is not customary to think explicitly in
terms of populations, samples and estimates.  Nevertheless, it's
implied, as ML people do talk about predicting new data from the model
fitted on the original data.  For the model to be useful, the new data
needs to come from the same source as the original --- what
statisticians call a population.

We will usually think in terms of sample data here.

\section{Probability, Expected Value and Variance}

We will speak in terms of a \textit{repeatable experiment}, which again
could be physical or conceptual.

We think of probability as the long-run proportion of the time some
event occurs.  Say we toss a fair coin.  What do we mean by
$P(\textrm{heads} = 0.5)$?  Here our repeatable experiment is tossing the
coin.  If we were to perform that experiment many times ---
ideally, infinitely many times --- then in the long run, 50\% of the
repetitions would give us heads.

Now suppose our experiment, say a game, is to keep tossing a coin until
we get three consecutive heads.  Let $X$ denote the number of tosses
needed.  Then for instance $P(X = 4) = 0.5^4 = 0.0625$ (we get a tail
then three heads).  Imagine doing this experiment infinitely many times:
We toss the coin until we get three consecutive heads, and record $X$;
we toss the coin until we get three consecutive heads, and record $X$;
we toss the coin until we get three consecutive heads, and record $X$;
and so on.  This would result in infinitely many $X$ values.  Then in
the long run, 6.25\% of the $X$ values would be 4.

The \textit{expected value} $E(X)$ of a random variable $X$ is its long-run
average value over infinitely many repetitions of the experiment.  In
that 3-consecutive heads game above, it can be shown that $E(X) = 14.7$.
In other words, if we were to play the game infinitely many times,
yielding infinitely $X$ values, their long-run average would be 14.7.

If there is no danger of ambiguity, we usually omit the parentheses,
writing $EX$ instead of $E(X)$.

The \textit{variance} of a random variable is a measure of its
dispersion, i.e.\ how much it varies from one repetition to the next.
It is defined as $Var(X) = E[(X - EX)^2]$.

Say we have a population of people and our our experiment is to 
randomly draw one person from the population, denoting that person's
height by $H$.  Then intuitively, $EH$ will be the mean height of all
the people in the population, traditionally written as $\mu$.

\section{Regression Models} 

These models, both \textit{parametric} and \textit{nonparametric},
\textbf{form the very core of statistics and machine learning (ML)}.  Their
importance cannot be overemphasized.\footnote{For many, the term
\textit{regression analysis} connotes a linear parametric model.  But
actually the term is much more general, defined to be the conditional
mean as discussed below.  Most ML techniques are nonparametric, as
explained below, but are still regression methods.}

\subsection{Definition}

Suppose we are predicting a variable $Y$ from a vector $X$ of variables,
say predicting human weight from the vector (height,age).  The
\textit{regression function} at $t = (t_1,t_2)$ of $Y$ on $X$ is defined
to be the mean weight of all people in the subpopulation consisting of
all people of height $t_1$ and age $t_2$.

Let $W$, $H$ and $A$ denote weight, height and age.  We write the
regression function as the \textit{conditional expectation} of $W$ given
$H$ and $A$, 

\begin{equation}
\label{regdef}
E(W ~| H=t_1, A=t_2)
\end{equation}

If, say $E(W ~| H=70, A=28) = 162$, it means that the mean weight of all
people in the subpopulation consisting of 28-year-olds of height 70 is
162.

Note that in (\ref{regdef}), the expression has a different value for
each $(t_1,t_2)$ pair.  So it is a \underline{function} of $t_1$ and
$t_2$.  This is called the \textit{regression function} of $W$ on $H$
and $A$.

\subsection{Prediction}

Say we have a person whose height and age are 70 and 28, but with
unknown weight.  It can be shown that the optimal (under a certain
criterion) predictor of her weight is $E(W ~| H=70, A=28) = 162$.

\subsection{Estimation}

The regression function is an attribute of the population.  Yet all we
have is sample data.  How do we estimate the regression function from
our data?

\textit{Nonparametric:}

Intuitively, we could use a nearest-neighbor approach.  To estimate
$E(W ~| H=70, A=28)$, we could find, say, the 25 people in our
sample for whom $(H,A)$ is closest to (70,28), and average their weights
to produce our estimate of $E(W ~| H=70, A=28)$.  

This kind of approach is common in ML.  The famous \textit{random
forests} method is basically a more complex form of kNN, as we will see
in Chapter \ref{chap:covars}.  (If the reader is familiar with
\textit{neural networks}, she may be surprised that this technique is
parametric.  Again, more in Chapter \ref{chap:covars}.)

Statisticians also use methods like kNN.  In fact, kNN and random
forests were invented by statisticians.  But more commonly, statistics
uses \textit{parametric} methods, as follows.

\textit{Parametric:}

The basic idea is to assume the regression function is linear in
\underline{parameters} $\beta_i$, e.g.

\begin{equation}
\textrm{mean weight} = \beta_0 + \beta_1 ~ \textrm{height} + \beta_2 ~ \textrm{age}
\end{equation}

for some unknown values of the $\widehat{\beta}_i$.

Make sure to take careful note of the word ``mean''!  Clearly, the
weights of \underline{individual} people are not linear functions of
their height and age.

As noted, the $\beta_i$ are unknown, and need to be estimated
from our sample data.  The estimates will be denoted
$\widehat{\beta}_i$.  They are obtained by minimizing a certain sum of
squares, to be discussed in Section \ref{lmdetails}.

In R, the workhorse regression estimator is the \textbf{lm()} function.
Let's apply this to the MovieLens data, predicting rating from age and
gender.  We'll define the latter as 1 for male, 0 for female.  We find
that our estimated regression function of rating on age and gender is

\begin{equation}
\textrm{estimated mean rating} = 3.3599 + 0.005311 ~ \textrm{age} 
- 0.0069 ~ \textrm{gender}
\end{equation}

Actually, this shows that age and gender are pretty weak predictors of
movie rating, which you will recall is on a scale of 1 to 5.  A 10-year
difference in age raised the predicted rating only by about 0.05!  The
effect of gender is small too.  And while it is interesting to see that
older people tend to give slighly higher ratings, as do women, we must
keep in mind that the magnitude of the effect here is
small.\footnote{You may be familiar with the term \textit{statistically
significant}.  It is generally recognized today that this term can be
quite misleading.  This is beyond the scope of this book, but suffice it
to say that although age and gender are statistically significant above
(details in the R output), their practical importance as predictors here
is essentially nil.  See R. Wasserstein and N. Lazar, The ASA's
Statement on p-Values: Context, Process, and Purpose, \textit{The
American Statistician}, June 2016.}

Here is the annotated code:

\begin{lstlisting}

# read (user,item,rating,transID) data; name the columns
ratings <- read.table('u.data') 
names(ratings) <- c('usernum','movienum','rating','transID') 
# read demographic data
demog <- read.table('u.user',sep='|') 
names(demog) <- c('usernum','age','gender','occ','ZIP') 
# merge (database 'join' op)
u.big <- merge(ratings,demog,by.x=1,by.y=1) 
u <- u.big[,c(1,3,5,6)] 
# fit linear model
lmout <- lm(rating ~ age+gender,data=u) 

\end{lstlisting}

\subsection{Details of Linear Regression Estimation}
\label{lmdetails}

In the weight-height-age example, say, we form 

\begin{equation}
\label{rss}
r =
\sum_{i=1}^n [W_i - (b_0 + b_1 H_i + b_2 A_i)]^2
\end{equation}

where $W_i$ is the weight of the i$^{th}$ person in our sample data and
so on. This is the sum of squared prediction errors.  We take derivatives
with respect to the $b_k$ to minimize, then set $\widehat{\beta}_k$ to
the minimizing $b_k$.  

Though R will do the minimizing for us, it is worth having an idea how
it works, especially as more practice in following matrix-centric
derivations.  To get a glimpse of this, we look at a matrix formulation, as
follows.  Let $A$ denote the matrix of predictor values, with a 1s
column tacked on at the left.  In the above example, row 12, say, of $A$
would consist of a 1, followed by the height and age of the 12$^{th}$
person in our sample.  Let $D$ denote the vector of weights, so that
$D_{12}$ is the weight of the 12$^{th}$ person in our sample.  Finally,
let $b$ denote the vector of $b_k$.  Then

\begin{equation}
\label{}
r = (D - A b)' (D - Ab)
\end{equation}

(Write it out to see this.)

Write the \textit{gradient} of $r$ with respect to $b$,

\begin{equation}
\frac{\partial r}{\partial b} = (
\frac{\partial r}{\partial b_0},
\frac{\partial r}{\partial b_1},
...
\frac{\partial r}{\partial b_p}
)'
\end{equation}

where $p$ is the number of predictor variables.

It can be shown that for a vector $u$,

\begin{equation}
\frac{\partial u'u}{\partial b} = 2u
\end{equation}

(analogous to the scalar relations $d (u^2) /du = 2u$; again, this is
seen by writing the expressions out).

Setting $u = D - Ab$ and applying the Chain Rule (adapted for
gradients), we get

\begin{equation}
\frac{\partial r}{\partial b} = 2 (-A') (D - Ab) 
\end{equation}

The the gradient to 0 and solving for $b$, we have

\begin{equation}
0 = A'D - A'Ab
\end{equation}

so that the minimizing $b$ is

\begin{equation}
b = (A'A)^{-1} A'D
\end{equation}

This is what \textbf{lm()} computes in finding the $\widehat{\beta}_k$.

\subsection{Categorical Variables (Predictor, Response)}

A \textit{categorical} variable is one that codes categories.  In our RS
context, for instance, a user's postal code --- ZIP Code, in the US ---
may be a helpful predictor of a rating.  Yet it cannot be treated in
\textbf{lm()}, say as a numeric variable.  After all, the ZIP Code
90024, for example, is not ``twice as good'' as 45002.

\section{Bias, Variance, Overfitting and p-Hacking}

By far the most vexing issue in statistics and machine learning is that
of \textit{overfitting}.

